#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
cut_highlights.py
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1. –°–∫–∞—á–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ—Ä–≤—å—é —Å YouTube –ø–æ —Å—Å—ã–ª–∫–µ INTERVIEW_URL
2. –í—ã—Ç—è–≥–∏–≤–∞–µ—Ç –ª—É—á—à—É—é –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫—É (m4a ‚ñ∏ fallback ‚Üí –ª—é–±–æ–π bestaudio)
3. –û—Ç–¥–∞—ë—Ç –µ—ë –≤ Whisper (o3 –∏–ª–∏ gpt-4o-mini) –∏ –ø–æ–ª—É—á–∞–µ—Ç JSON-—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
4. –î–µ–ª–∏—Ç –≤—ã–ø—É—Å–∫ –Ω–∞ N_SEGMENTS –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã
5. –ö–∞–∂–¥–æ–º—É —Å–µ–≥–º–µ–Ω—Ç—É ¬´–æ–±—Ä–µ–∑–∞–µ—Ç¬ª 30 —Å ¬± 10 —Å, –∫–ª–∞–¥—ë—Ç –≤ scripts/audio/voice_*.mp3
   ‚Äî –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π —Å–±–æ—Ä–∫–∏ —à–æ—Ä—Ç–æ–≤ build_video.py
"""

# ‚îÄ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ‚Äî –º–µ–Ω—è–π—Ç–µ –ø–æ –≤–∫—É—Å—É ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
INTERVIEW_URL = "https://www.youtube.com/watch?v=zV7lrWumc7U"   # –∑–∞–º–µ–Ω–∏—Ç–µ!
N_SEGMENTS    = 4      # –ø–æ 2 —à–æ—Ä—Ç–∞ –≤ –¥–µ–Ω—å ‚Üí 4 —Å–µ–≥–º–µ–Ω—Ç–∞ –Ω–∞ 2 –¥–Ω—è
CLIP_SEC      = 30     # –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
LEADING_SEC   = 10     # —Å–¥–≤–∏–≥–∞–µ–º –Ω–∞—á–∞–ª–æ –∫—É—Å–æ—á–∫–∞, —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞–ª–æ —Å–ª–æ–≤–∞
MODEL         = "whisper-1"   # –∏–ª–∏ "o3"
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

import os, io, json, math, shutil, subprocess, tempfile, textwrap, uuid
from pathlib import Path

import yt_dlp, pydub
from pydub import AudioSegment
import openai

# –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–∞
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
assert OPENAI_API_KEY, "–ù–µ—Ç OPENAI_API_KEY"
client = openai.OpenAI(api_key=OPENAI_API_KEY)

ROOT_DIR   = Path(__file__).parent
AUDIO_DIR  = ROOT_DIR / "audio"
AUDIO_DIR.mkdir(exist_ok=True, parents=True)

# ---------------------------------------------------------------------------#
def download_audio(url: str) -> Path:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –∏—Ç–æ–≥–æ–≤–æ–º—É .m4a"""
    with tempfile.TemporaryDirectory() as tmp:
        tmpdir = Path(tmp)
        out    = tmpdir / "full.%(ext)s"

        ydl_opts = {
            # 1) m4a (–æ–±—ã—á–Ω–æ = itag 140), 2) –ª—é–±–æ–π bestaudio, 3) –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ
            "format": "bestaudio[ext=m4a]/bestaudio/best",
            "outtmpl": str(out),
            "quiet": True,
            # –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ m4a, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            "postprocessors": [
                {
                    "key": "FFmpegExtractAudio",
                    "preferredcodec": "m4a",
                    "preferredquality": "192",
                }
            ],
        }
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])

        final = out.with_suffix(".m4a")
        return final if final.exists() else list(tmpdir.glob("*.m4a"))[0]

# ---------------------------------------------------------------------------#
def transcribe(path: Path) -> list[dict]:
    """–û—Ç–¥–∞—ë–º —Ñ–∞–π–ª –≤ Whisper, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤ —Å —Ç–∞–π–º–∏–Ω–≥–æ–º"""
    print("üìù Whisper‚Ä¶ (~—Ä–µ–∞–ª. –≤—Ä–µ–º—è)")

    with path.open("rb") as f:
        transcript = client.audio.transcriptions.create(
            model=MODEL,
            file=f,
            response_format="verbose_json"
        )

    return transcript.words  # list[{word,start,end}]

# ---------------------------------------------------------------------------#
def split_to_segments(words: list[dict], n: int) -> list[tuple[float,float]]:
    """–î–µ–ª–∏–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ n —Ä–∞–≤–Ω—ã—Ö –∫—É—Å–∫–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º (start,end) —Å–µ–∫—É–Ω–¥"""
    full_sec = words[-1]["end"]
    chunk    = full_sec / n
    bounds   = []
    for i in range(n):
        t0 = max(0, i*chunk + LEADING_SEC)
        t1 = t0 + CLIP_SEC
        bounds.append((t0, t1))
    return bounds

# ---------------------------------------------------------------------------#
def cut_clips(src: Path, segments: list[tuple[float,float]]) -> None:
    """–†–µ–∂–µ—Ç –∞—É–¥–∏–æ –Ω–∞ –∫–ª–∏–ø—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç them ‚Üí scripts/audio/voice_*.mp3"""
    audio = AudioSegment.from_file(src)
    for i, (t0, t1) in enumerate(segments, 1):
        clip = audio[t0*1000 : t1*1000]
        fname = AUDIO_DIR / f"voice_{i}.mp3"
        clip.export(fname, format="mp3", bitrate="192k")
        print(f"üé§  {fname.name}  {len(clip)//1000:>3d}s")

# ---------------------------------------------------------------------------#
def main() -> None:
    print("‚è¨  –°–∫–∞—á–∏–≤–∞–µ–º –∞—É–¥–∏–æ‚Ä¶")
    m4a = download_audio(INTERVIEW_URL)
    print(f"   ‚úî {m4a.stat().st_size/1e6:.1f} MB")

    words = transcribe(m4a)
    segments = split_to_segments(words, N_SEGMENTS)
    cut_clips(m4a, segments)

    print("\n‚úÖ  –ì–æ—Ç–æ–≤–æ: –∞—É–¥–∏–æ –ª–µ–∂–∏—Ç –≤ scripts/audio/*.mp3")

if __name__ == "__main__":
    main()
